{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-06-22T17:55:17.9239447Z",
              "execution_start_time": "2023-06-22T17:55:17.7652631Z",
              "livy_statement_state": "available",
              "parent_msg_id": "8066af4d-2fa8-4f95-8232-218c36ba0690",
              "queued_time": "2023-06-22T17:52:26.1614666Z",
              "session_id": "67",
              "session_start_time": "2023-06-22T17:52:26.2269388Z",
              "spark_jobs": null,
              "spark_pool": "sparkpoolforml",
              "state": "finished",
              "statement_id": 2
            },
            "text/plain": [
              "StatementMeta(sparkpoolforml, 67, 2, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def getSecret(secretName):\n",
        "    linked_service = \"ifmpmvault\"\n",
        "    akv_name = \"ifm-vault\"\n",
        "\n",
        "    # Fetch the key from Azure Key Vault\n",
        "    secretValue = mssparkutils.credentials.getSecret(\n",
        "        linkedService=linked_service,\n",
        "        akvName=akv_name, \n",
        "        secret=secretName)\n",
        "    return secretValue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-06-22T18:00:36.6596367Z",
              "execution_start_time": "2023-06-22T18:00:11.3865593Z",
              "livy_statement_state": "available",
              "parent_msg_id": "da9bf5ab-25e0-4efb-b67a-6bd9433ec3fa",
              "queued_time": "2023-06-22T18:00:11.2038263Z",
              "session_id": "67",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolforml",
              "state": "finished",
              "statement_id": 3
            },
            "text/plain": [
              "StatementMeta(sparkpoolforml, 67, 3, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database already exists\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DataFrame[key: string, value: string]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    spark.sql(\"CREATE DATABASE dataverse_d365env_generated_data\")\n",
        "except:\n",
        "    print(\"Database already exists\")\n",
        "\n",
        "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\") #to read the dataverse datetime columns in spark3.x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-06-22T18:01:54.8500643Z",
              "execution_start_time": "2023-06-22T18:01:52.9485859Z",
              "livy_statement_state": "available",
              "parent_msg_id": "41282467-a9f1-4812-9196-9c3e49c775ad",
              "queued_time": "2023-06-22T18:01:52.7993534Z",
              "session_id": "67",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolforml",
              "state": "finished",
              "statement_id": 4
            },
            "text/plain": [
              "StatementMeta(sparkpoolforml, 67, 4, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "file_system_name = getSecret('file-system-name')\n",
        "data_lake_account_name = getSecret('data-lake-account-name')\n",
        "basepath = f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-06-22T18:02:50.1367293Z",
              "execution_start_time": "2023-06-22T18:01:57.9272236Z",
              "livy_statement_state": "available",
              "parent_msg_id": "b5e7b90d-9148-465a-859a-b5529ba6bc41",
              "queued_time": "2023-06-22T18:01:57.784303Z",
              "session_id": "67",
              "session_start_time": null,
              "spark_jobs": null,
              "spark_pool": "sparkpoolforml",
              "state": "finished",
              "statement_id": 5
            },
            "text/plain": [
              "StatementMeta(sparkpoolforml, 67, 5, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tableslist = ['connection',\n",
        "    'incident',\n",
        "    'msdyn_customerasset',\n",
        "    'msdyn_iotalert',\n",
        "    'msdyn_iotdevice',\n",
        "    'msdyn_workorder']\n",
        "\n",
        "for tablename in tableslist:\n",
        "    file_path =  basepath + '/dataverse_d365_generated/' + tablename + '.csv'\n",
        "    df = spark.read.load(file_path, format='csv', header=True,inferSchema=True)\n",
        "    df.write.mode(\"overwrite\").saveAsTable(\"dataverse_d365env_generated_data.\" + tablename)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
