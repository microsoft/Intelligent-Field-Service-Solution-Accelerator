{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def getSecret(secretName):\n",
        "    linked_service = \"ifmpmvault\"\n",
        "    akv_name = \"ifm-vault\"\n",
        "\n",
        "    # Fetch the key from Azure Key Vault\n",
        "    secretValue = mssparkutils.credentials.getSecret(\n",
        "        linkedService=linked_service,\n",
        "        akvName=akv_name, \n",
        "        secret=secretName)\n",
        "    return secretValue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "feat_data = spark.sql('''select * from machine_data_features''')\n",
        "\n",
        "split_date = \"2022-12-21\" #\"2015-10-30\"\n",
        "training = feat_data.filter(feat_data.dt_truncated < split_date)\n",
        "testing = feat_data.filter(feat_data.dt_truncated >= split_date)\n",
        "\n",
        "drop_cols =['msdyn_customerassetid','dt_truncated','model','failure','msdyn_name', 'msdyn_productname', 'modifiedon','component', 'failure']\n",
        "# Remove the extra names if that are in the input_features list\n",
        "input_features = [x for x in feat_data.columns if x not in set(drop_cols)]\n",
        "\n",
        "df_train = training.select(input_features).toPandas()\n",
        "\n",
        "# print(training.count(),testing.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "all_classes = Counter(df_train['label_e'])\n",
        "majority_class = all_classes.most_common(1)\n",
        "minority_classes = all_classes.most_common()[1:]\n",
        "\n",
        "minority_classes_size = 0\n",
        "for c in minority_classes:\n",
        "    minority_classes_size += c[1]\n",
        "\n",
        "desired_minority_classes_size = df_train['label_e'].count() * 0.5\n",
        "# print(desired_minority_classes_size)\n",
        "\n",
        "scale = int(int(desired_minority_classes_size) / minority_classes_size)\n",
        "# print(scale)\n",
        "\n",
        "df_0 = df_train[df_train['label_e'] == 0]\n",
        "\n",
        "df_F1 = df_train[df_train['label_e'] == 1]\n",
        "df_F1 = resample(df_F1,replace=True,n_samples=(len(df_F1) * scale),random_state=42)\n",
        "\n",
        "df_F2 = df_train[df_train['label_e'] == 2]\n",
        "df_F2 = resample(df_F2,replace=True,n_samples=(len(df_F2) * scale),random_state=42)\n",
        "\n",
        "df_F3 = df_train[df_train['label_e'] == 3]\n",
        "df_F3 = resample(df_F3,replace=True,n_samples=(len(df_F3) * scale),random_state=42)\n",
        "\n",
        "df_F4 = df_train[df_train['label_e'] == 4]\n",
        "df_F4 = resample(df_F4,replace=True,n_samples=(len(df_F4) * scale),random_state=42)\n",
        "\n",
        "df_train_upsampled = pd.concat([df_0, df_F1,df_F2,df_F3,df_F4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
        "from azureml.core.model import Model\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "\n",
        "subscription_id = getSecret('subscription-id')\n",
        "resource_group = getSecret('resource-group')\n",
        "workspace_name = getSecret('workspace-name')\n",
        "\n",
        "ws = Workspace(workspace_name = workspace_name,\n",
        "               subscription_id = subscription_id,\n",
        "               resource_group = resource_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# increase  the interation and experiment_timeout_hours as needed \n",
        "automl_settings = {\n",
        "    \"iterations\": 10,\n",
        "    \"n_cross_validations\": 5,\n",
        "    \"primary_metric\": 'AUC_weighted',\n",
        "    \"enable_early_stopping\": True,\n",
        "    \"max_concurrent_iterations\": 5, \n",
        "    \"model_explainability\":True,\n",
        "    \"experiment_timeout_hours\": 0.25\n",
        "}\n",
        "automl_config = AutoMLConfig(task = 'classification',\n",
        "                             training_data = df_train_upsampled,\n",
        "                             label_column_name = 'label_e',\n",
        "                             **automl_settings\n",
        "                            )\n",
        "experiment = Experiment(ws, \"PredictiveMaintenanceExperiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "local_run = experiment.submit(automl_config, show_output=False)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
