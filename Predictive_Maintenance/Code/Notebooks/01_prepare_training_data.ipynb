{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getSecret(secretName):\n",
        "    linked_service = \"ifmpmvault\"\n",
        "    akv_name = \"ifm-vault\"\n",
        "\n",
        "    # Fetch the key from Azure Key Vault\n",
        "    secretValue = mssparkutils.credentials.getSecret(\n",
        "        linkedService=linked_service,\n",
        "        akvName=akv_name, \n",
        "        secret=secretName)\n",
        "    return secretValue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "data_lake_account_name = getSecret('data-lake-account-name')\n",
        "file_system_name = getSecret('file-system-name')\n",
        "\n",
        "basepath = f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {},
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "telemetry_path = f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/msdyn_iothub_generated/msdyn-iothub-ii3ywz6swv5z2/*/*/*' #2022/10/1' \n",
        "telemetry = spark.read.load(telemetry_path, format='json')\n",
        "\n",
        "telemetry = telemetry.select(\"SystemProperties.connectionDeviceId\",\"Body.Timestamp\",\"Body.volt\",\"Body.rotate\",\"Body.pressure\",\"Body.vibration\")\n",
        "cols = ['connectionDeviceId','tdatetime','volt','rotate','pressure','vibration']\n",
        "telemetry = telemetry.toDF(*cols)\n",
        "\n",
        "df_assets = spark.sql('''select msdyn_customerassetid, a.msdyn_name, i.msdyn_name as connectionDeviceId\n",
        "from dataverse_d365env_generated_data.msdyn_customerasset as a \n",
        "left join dataverse_d365env_generated_data.connection as c on a.msdyn_customerassetid = c.record1id\n",
        "left join dataverse_d365env_generated_data.msdyn_iotdevice as i on i.msdyn_iotdeviceid = c.record2id\n",
        "''')\n",
        "telemetry = telemetry.join(df_assets,on='connectionDeviceId').select('msdyn_customerassetid','tdatetime','volt','rotate','pressure','vibration')\n",
        "\n",
        "telemetry = telemetry.groupBy(['msdyn_customerassetid','tdatetime']).agg(max(\"volt\").alias(\"volt\"),max(\"rotate\").alias(\"rotate\"),max(\"pressure\").alias(\"pressure\"),max(\"vibration\").alias(\"vibration\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# telemetry = spark.sql('''select t.*, machine_guid as msdyn_customerassetid, t.datetime as msdyn_alerttime \n",
        "# from machine_telemetry_data as t inner join machine_data as m on t.machineID = m.machineID''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# rolling mean and standard deviation\n",
        "# Temporary storage for rolling means\n",
        "tel_mean = telemetry\n",
        "\n",
        "# Which features are we interested in telemetry data set\n",
        "rolling_features = ['volt','rotate', 'pressure', 'vibration']\n",
        "      \n",
        "# n hours = n * 3600 seconds  \n",
        "time_val = 12 * 3600\n",
        "\n",
        "# Choose the time_val hour timestamps to align the data\n",
        "# dt_truncated looks at the column named \"datetime\" in the current data set.\n",
        "# remember that Spark is lazy... this doesn't execute until it is in a withColumn statement.\n",
        "dt_truncated = ((round(unix_timestamp(col(\"tdatetime\")) / time_val) * time_val).cast(\"timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.functions import col, unix_timestamp, round\n",
        "from pyspark.sql.functions import datediff\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# We choose windows for our rolling windows 12hrs, 24 hrs and 36 hrs\n",
        "lags = [12, 24, 36]\n",
        "\n",
        "# align the data\n",
        "for lag_n in lags:\n",
        "    wSpec = Window.partitionBy('msdyn_customerassetid').orderBy('tdatetime').rowsBetween(1-lag_n, 0)\n",
        "    for col_name in rolling_features:\n",
        "        tel_mean = tel_mean.withColumn(col_name+'_rollingmean_'+str(lag_n), \n",
        "                                       F.avg(col(col_name)).over(wSpec))\n",
        "        tel_mean = tel_mean.withColumn(col_name+'_rollingstd_'+str(lag_n), \n",
        "                                       F.stddev(col(col_name)).over(wSpec))\n",
        "\n",
        "# Calculate lag values...\n",
        "telemetry_feat = (tel_mean.withColumn(\"dt_truncated\", dt_truncated)\n",
        "                  .drop('volt', 'rotate', 'pressure', 'vibration')\n",
        "                  .fillna(0)\n",
        "                  .groupBy(\"msdyn_customerassetid\",\"dt_truncated\")\n",
        "                  .agg(F.mean('volt_rollingmean_12').alias('volt_rollingmean_12'),\n",
        "                       F.mean('rotate_rollingmean_12').alias('rotate_rollingmean_12'), \n",
        "                       F.mean('pressure_rollingmean_12').alias('pressure_rollingmean_12'), \n",
        "                       F.mean('vibration_rollingmean_12').alias('vibration_rollingmean_12'), \n",
        "                       F.mean('volt_rollingmean_24').alias('volt_rollingmean_24'),\n",
        "                       F.mean('rotate_rollingmean_24').alias('rotate_rollingmean_24'), \n",
        "                       F.mean('pressure_rollingmean_24').alias('pressure_rollingmean_24'), \n",
        "                       F.mean('vibration_rollingmean_24').alias('vibration_rollingmean_24'),\n",
        "                       F.mean('volt_rollingmean_36').alias('volt_rollingmean_36'),\n",
        "                       F.mean('vibration_rollingmean_36').alias('vibration_rollingmean_36'),\n",
        "                       F.mean('rotate_rollingmean_36').alias('rotate_rollingmean_36'), \n",
        "                       F.mean('pressure_rollingmean_36').alias('pressure_rollingmean_36'), \n",
        "                       F.stddev('volt_rollingstd_12').alias('volt_rollingstd_12'),\n",
        "                       F.stddev('rotate_rollingstd_12').alias('rotate_rollingstd_12'), \n",
        "                       F.stddev('pressure_rollingstd_12').alias('pressure_rollingstd_12'), \n",
        "                       F.stddev('vibration_rollingstd_12').alias('vibration_rollingstd_12'), \n",
        "                       F.stddev('volt_rollingstd_24').alias('volt_rollingstd_24'),\n",
        "                       F.stddev('rotate_rollingstd_24').alias('rotate_rollingstd_24'), \n",
        "                       F.stddev('pressure_rollingstd_24').alias('pressure_rollingstd_24'), \n",
        "                       F.stddev('vibration_rollingstd_24').alias('vibration_rollingstd_24'),\n",
        "                       F.stddev('volt_rollingstd_36').alias('volt_rollingstd_36'),\n",
        "                       F.stddev('rotate_rollingstd_36').alias('rotate_rollingstd_36'), \n",
        "                       F.stddev('pressure_rollingstd_36').alias('pressure_rollingstd_36'), \n",
        "                       F.stddev('vibration_rollingstd_36').alias('vibration_rollingstd_36'), ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# errors = spark.sql('select e.* from machine_errors_data as e inner join machine_data as m on e.machineID = m.machineID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "errors = spark.sql('''select a.msdyn_customerassetid, reverse(split(i.msdyn_name,'_'))[0] as component, msdyn_alerttime from dataverse_d365env_generated_data.msdyn_customerasset as a \n",
        "left join dataverse_d365env_generated_data.connection as c on a.msdyn_customerassetid = c.record1id\n",
        "left join dataverse_d365env_generated_data.msdyn_iotdevice as i on i.msdyn_iotdeviceid = c.record2id\n",
        "inner join dataverse_d365env_generated_data.msdyn_iotalert as ia on ia.msdyn_customerasset = a.msdyn_customerassetid\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# create a column for each errorID \n",
        "error_ind = (errors.groupBy(\"msdyn_customerassetid\",\"msdyn_alerttime\",\"component\").pivot('component')\n",
        "             .agg(F.count('msdyn_customerassetid').alias('dummy')).drop('component').fillna(0)\n",
        "             .groupBy(\"msdyn_customerassetid\",\"msdyn_alerttime\")\n",
        "             .agg(F.sum('1').alias('error1sum'), \n",
        "                  F.sum('2').alias('error2sum'), \n",
        "                  F.sum('2').alias('error3sum'), \n",
        "                  F.sum('4').alias('error4sum')))\n",
        "\n",
        "# join the telemetry data with errors\n",
        "error_count = (telemetry.join(error_ind, \n",
        "                              ((telemetry['msdyn_customerassetid'] == error_ind['msdyn_customerassetid']) \n",
        "                               & (telemetry['tdatetime'] == error_ind['msdyn_alerttime'])), \"left\")\n",
        "               .drop('volt', 'rotate', 'pressure', 'vibration')\n",
        "               .drop(error_ind.msdyn_customerassetid).drop(error_ind.msdyn_alerttime))\n",
        "            #    .fillna(0))\n",
        "\n",
        "error_features = ['error1sum','error2sum', 'error3sum', 'error4sum']\n",
        "\n",
        "wSpec = Window.partitionBy('msdyn_customerassetid').orderBy('tdatetime').rowsBetween(1-24, 0)\n",
        "for col_name in error_features:\n",
        "    # We're only interested in the erros in the previous 24 hours.\n",
        "    error_count = error_count.withColumn(col_name+'_rollingmean_24', \n",
        "                                         F.avg(col(col_name)).over(wSpec))\n",
        "\n",
        "error_feat = (error_count.withColumn(\"dt_truncated\", dt_truncated)\n",
        "              .drop('error1sum', 'error2sum', 'error3sum', 'error4sum').fillna(0)\n",
        "              .groupBy(\"msdyn_customerassetid\",\"dt_truncated\")\n",
        "              .agg(F.mean('error1sum_rollingmean_24').alias('error1sum_rollingmean_24'), \n",
        "                   F.mean('error2sum_rollingmean_24').alias('error2sum_rollingmean_24'), \n",
        "                   F.mean('error3sum_rollingmean_24').alias('error3sum_rollingmean_24'), \n",
        "                   F.mean('error4sum_rollingmean_24').alias('error4sum_rollingmean_24')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# maint = spark.sql('select * from machine_maint_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "maint = spark.sql('''select a.msdyn_customerassetid, msdyn_iotalertname, reverse(split(i.msdyn_name,'_'))[0] as component, wo.modifiedon\n",
        "    from dataverse_d365env_generated_data.msdyn_customerasset as a \n",
        "    inner join dataverse_d365env_generated_data.connection as c on a.msdyn_customerassetid = c.record1id\n",
        "    inner join dataverse_d365env_generated_data.msdyn_iotdevice as i on i.msdyn_iotdeviceid = c.record2id\n",
        "    inner join dataverse_d365env_generated_data.msdyn_workorder as wo on wo.msdyn_customerasset = a.msdyn_customerassetid and i.msdyn_iotdeviceid = wo. msdyn_iotalertname''')\n",
        "\n",
        "# display(maint.take(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# create a column for each component replacement\n",
        "import pyspark.sql.functions as F\n",
        "maint_replace = (maint.groupBy(\"msdyn_customerassetid\",\"modifiedon\",\"component\").pivot('component')\n",
        "                 .agg(F.count('msdyn_customerassetid').alias('dummy')).fillna(0)\n",
        "                 .groupBy(\"msdyn_customerassetid\",\"modifiedon\")\n",
        "                 .agg(F.sum('1').alias('component1_age'), \n",
        "                      F.sum('2').alias('component2_age'), \n",
        "                      F.sum('3').alias('component3_age'),\n",
        "                      F.sum('4').alias('component4_age')))\n",
        "\n",
        "maint_replace = maint_replace.withColumnRenamed('modifiedon','datetime_maint')\n",
        "\n",
        "print(maint_replace.count())\n",
        "# display(maint_replace.take(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# We want to align the component information on telemetry features timestamps.\n",
        "telemetry_times = (telemetry_feat.select(telemetry_feat.msdyn_customerassetid, telemetry_feat.dt_truncated)\n",
        "                   .withColumnRenamed('dt_truncated','datetime_tel'))\n",
        "\n",
        "# Grab component 1 records\n",
        "maint_comp1 = (maint_replace.where(col(\"component1_age\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
        "               .drop('component2_age', 'component3_age', 'component4_age'))\n",
        "\n",
        "# Within each machine, get the last replacement date for each timepoint\n",
        "maint_tel_comp1 = (telemetry_times.join(maint_comp1, \n",
        "                                        ((telemetry_times ['msdyn_customerassetid']== maint_comp1['msdyn_customerassetid']) \n",
        "                                         & (telemetry_times ['datetime_tel'] > maint_comp1['datetime_maint']) \n",
        "                                         & ( maint_comp1['component1_age'] == '1')))\n",
        "                   .drop(maint_comp1.msdyn_customerassetid))\n",
        "\n",
        "# Calculate the number of days between replacements\n",
        "comp1 = (maint_tel_comp1.withColumn(\"sincelastcomp1\", \n",
        "                                    datediff(maint_tel_comp1.datetime_tel, maint_tel_comp1.datetime_maint))\n",
        "         .drop(maint_tel_comp1.datetime_maint).drop(maint_tel_comp1.component1_age))\n",
        "\n",
        "print(comp1.count())\n",
        "# display(comp1.take(5))\n",
        "# display(comp1.filter(comp1.machineID == '625').orderBy(comp1.datetime_tel).limit(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Grab component 2 records\n",
        "maint_comp2 = (maint_replace.where(col(\"component2_age\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
        "               .drop('component1_age', 'component3_age', 'component4_age'))\n",
        "\n",
        "# Within each machine, get the last replacement date for each timepoint\n",
        "maint_tel_comp2 = (telemetry_times.join(maint_comp2, \n",
        "                                        ((telemetry_times ['msdyn_customerassetid']== maint_comp2['msdyn_customerassetid']) \n",
        "                                         & (telemetry_times ['datetime_tel'] > maint_comp2['datetime_maint']) \n",
        "                                         & ( maint_comp2['component2_age'] == '1')))\n",
        "                   .drop(maint_comp2.msdyn_customerassetid))\n",
        "\n",
        "# Calculate the number of days between replacements\n",
        "comp2 = (maint_tel_comp2.withColumn(\"sincelastcomp2\", \n",
        "                                    datediff(maint_tel_comp2.datetime_tel, maint_tel_comp2.datetime_maint))\n",
        "         .drop(maint_tel_comp2.datetime_maint).drop(maint_tel_comp2.component2_age))\n",
        "\n",
        "# print(comp2.count())\n",
        "# display(comp2.take(5))\n",
        "# display(comp2.filter(comp2.machineID == '625').orderBy(comp2.datetime_tel).limit(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Grab component 3 records\n",
        "maint_comp3 = (maint_replace.where(col(\"component3_age\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
        "               .drop('component1_age', 'component2_age', 'component4_age'))\n",
        "\n",
        "# Within each machine, get the last replacement date for each timepoint\n",
        "maint_tel_comp3 = (telemetry_times.join(maint_comp3, ((telemetry_times ['msdyn_customerassetid']==maint_comp3['msdyn_customerassetid']) \n",
        "                                                      & (telemetry_times ['datetime_tel'] > maint_comp3['datetime_maint']) \n",
        "                                                      & ( maint_comp3['component3_age'] == '1')))\n",
        "                   .drop(maint_comp3.msdyn_customerassetid))\n",
        "\n",
        "# Calculate the number of days between replacements\n",
        "comp3 = (maint_tel_comp3.withColumn(\"sincelastcomp3\", \n",
        "                                    datediff(maint_tel_comp3.datetime_tel, maint_tel_comp3.datetime_maint))\n",
        "         .drop(maint_tel_comp3.datetime_maint).drop(maint_tel_comp3.component3_age))\n",
        "\n",
        "\n",
        "# print(comp3.count())\n",
        "# comp3.filter(comp3.machineID == '625').orderBy(comp3.datetime_tel).limit(5).toPandas().head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Grab component 4 records\n",
        "maint_comp4 = (maint_replace.where(col(\"component4_age\") == '1').withColumnRenamed('datetime','datetime_maint')\n",
        "               .drop('component1_age', 'component2_age', 'component3_age'))\n",
        "\n",
        "# Within each machine, get the last replacement date for each timepoint\n",
        "maint_tel_comp4 = telemetry_times.join(maint_comp4, ((telemetry_times['msdyn_customerassetid']==maint_comp4['msdyn_customerassetid']) \n",
        "                                                     & (telemetry_times['datetime_tel'] > maint_comp4['datetime_maint']) \n",
        "                                                     & (maint_comp4['component4_age'] == '1'))).drop(maint_comp4.msdyn_customerassetid)\n",
        "\n",
        "# Calculate the number of days between replacements\n",
        "comp4 = (maint_tel_comp4.withColumn(\"sincelastcomp4\", \n",
        "                                    datediff(maint_tel_comp4.datetime_tel, maint_tel_comp4.datetime_maint))\n",
        "         .drop(maint_tel_comp4.datetime_maint).drop(maint_tel_comp4.component4_age))\n",
        "\n",
        "# print(comp4.count())\n",
        "# comp4.filter(comp4.machineID == '625').orderBy(comp4.datetime_tel).limit(5).toPandas().head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Join component 3 and 4\n",
        "comp3_4 = (comp3.join(comp4, ((comp3['msdyn_customerassetid'] == comp4['msdyn_customerassetid']) \n",
        "                              & (comp3['datetime_tel'] == comp4['datetime_tel'])), \"left\")\n",
        "           .drop(comp4.msdyn_customerassetid).drop(comp4.datetime_tel))\n",
        "\n",
        "# Join component 2 to 3 and 4\n",
        "comp2_3_4 = (comp2.join(comp3_4, ((comp2['msdyn_customerassetid'] == comp3_4['msdyn_customerassetid']) \n",
        "                                  & (comp2['datetime_tel'] == comp3_4['datetime_tel'])), \"left\")\n",
        "             .drop(comp3_4.msdyn_customerassetid).drop(comp3_4.datetime_tel))\n",
        "\n",
        "# Join component 1 to 2, 3 and 4\n",
        "comps_feat = (comp1.join(comp2_3_4, ((comp1['msdyn_customerassetid'] == comp2_3_4['msdyn_customerassetid']) \n",
        "                                      & (comp1['datetime_tel'] == comp2_3_4['datetime_tel'])), \"left\")\n",
        "               .drop(comp2_3_4.msdyn_customerassetid).drop(comp2_3_4.datetime_tel)\n",
        "               .groupBy(\"msdyn_customerassetid\", \"datetime_tel\")\n",
        "               .agg(F.max('sincelastcomp1').alias('sincelastcomp1'), \n",
        "                    F.max('sincelastcomp2').alias('sincelastcomp2'), \n",
        "                    F.max('sincelastcomp3').alias('sincelastcomp3'), \n",
        "                    F.max('sincelastcomp4').alias('sincelastcomp4'))\n",
        "               .fillna(0))\n",
        "\n",
        "# Choose the time_val hour timestamps to align the data\n",
        "dt_truncated = ((round(unix_timestamp(col(\"datetime_tel\")) / time_val) * time_val).cast(\"timestamp\"))\n",
        "\n",
        "# Collect data\n",
        "maint_feat = (comps_feat.withColumn(\"dt_truncated\", dt_truncated)\n",
        "              .groupBy(\"msdyn_customerassetid\",\"dt_truncated\")\n",
        "              .agg(F.mean('sincelastcomp1').alias('component1_age'), \n",
        "                   F.mean('sincelastcomp2').alias('component2_age'), \n",
        "                   F.mean('sincelastcomp3').alias('component3_age'), \n",
        "                   F.mean('sincelastcomp4').alias('component4_age')))\n",
        "\n",
        "# print(maint_feat.count())\n",
        "# display(maint_feat.limit(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# machines = spark.sql('select * from machine_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "spark.sql('refresh table dataverse_d365env_generated_data.msdyn_customerasset')\n",
        "machines = spark.sql('select msdyn_customerassetid,msdyn_name, msdyn_productname, modifiedon from dataverse_d365env_generated_data.msdyn_customerasset')\n",
        "machines = machines.withColumn(\"age\", floor(datediff(F.current_timestamp(), F.col(\"modifiedon\"))/365.25))\n",
        "# display(machines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "machines_feat = machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# join error features with component maintenance features\n",
        "error_maint = (error_feat.join(maint_feat, \n",
        "                               ((error_feat['msdyn_customerassetid'] == maint_feat['msdyn_customerassetid']) \n",
        "                                & (error_feat['dt_truncated'] == maint_feat['dt_truncated'])), \"left\")\n",
        "               .drop(maint_feat.msdyn_customerassetid).drop(maint_feat.dt_truncated))\n",
        "\n",
        "# now join that with machines features\n",
        "error_maint_feat = (error_maint.join(machines_feat, \n",
        "                                     ((error_maint['msdyn_customerassetid'] == machines_feat['msdyn_customerassetid'])), \"left\")\n",
        "                    .drop(machines_feat.msdyn_customerassetid))\n",
        "\n",
        "# Clean up some unecessary columns\n",
        "error_maint_feat = error_maint_feat.select([c for c in error_maint_feat.columns if c not in \n",
        "                                            {'error1sum', 'error2sum', 'error3sum', 'error4sum', 'error5sum'}])\n",
        "\n",
        "# join telemetry with error/maint/machine features to create final feature matrix\n",
        "final_feat = (telemetry_feat.join(error_maint_feat, \n",
        "                                  ((telemetry_feat['msdyn_customerassetid'] == error_maint_feat['msdyn_customerassetid']) \n",
        "                                   & (telemetry_feat['dt_truncated'] == error_maint_feat['dt_truncated'])), \"left\")\n",
        "              .drop(error_maint_feat.msdyn_customerassetid).drop(error_maint_feat.dt_truncated))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "final_feat.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# failures = spark.sql('select * from machine_failures_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "failures = spark.sql('''select a.msdyn_customerassetid as msdyn_customerassetid1, reverse(split(i.msdyn_name,'_'))[0] as component, in.modifiedon as incidenttime from dataverse_d365env_generated_data.msdyn_customerasset as a \n",
        "left join dataverse_d365env_generated_data.connection as c on a.msdyn_customerassetid = c.record1id\n",
        "left join dataverse_d365env_generated_data.msdyn_iotdevice as i on i.msdyn_iotdeviceid = c.record2id\n",
        "inner join dataverse_d365env_generated_data.msdyn_iotalert as ia on ia.msdyn_customerasset = a.msdyn_customerassetid\n",
        "inner join dataverse_d365env_generated_data.incident as in on in.msdyn_iotalert = ia.msdyn_iotalertid\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "dt_truncated = ((round(unix_timestamp(col(\"incidenttime\")) / time_val) * time_val).cast(\"timestamp\"))\n",
        "\n",
        "fail_diff = (failures.withColumn(\"dt_truncated\", dt_truncated)\n",
        "             .drop(failures.incidenttime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# map the failure data to final feature matrix\n",
        "labeled_features = (final_feat.join(fail_diff, \n",
        "                                    ((final_feat['msdyn_customerassetid'] == fail_diff['msdyn_customerassetid1']) \n",
        "                                     & (final_feat['dt_truncated'] == fail_diff['dt_truncated'])), \"left\")\n",
        "                    .drop(fail_diff.msdyn_customerassetid1)\n",
        "                    .drop(fail_diff.dt_truncated)\n",
        "                    .withColumn('failure', F.when(col('component') == \"1\", 1.0).otherwise(col('component')))\n",
        "                    .withColumn('failure', F.when(col('component') == \"2\", 2.0).otherwise(col('component')))\n",
        "                    .withColumn('failure', F.when(col('component') == \"3\", 3.0).otherwise(col('component')))\n",
        "                    .withColumn('failure', F.when(col('component') == \"4\", 4.0).otherwise(col('component')))\n",
        "                    )\n",
        "\n",
        "labeled_features = (labeled_features.withColumn(\"failure\", labeled_features.failure.cast(DoubleType())).fillna(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# # To get the frequency of each component failure \n",
        "# # df = labeled_features.select(labeled_features.failure).toPandas()\n",
        "# # df['failure'].value_counts()\n",
        "# labeled_features.groupBy('failure').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# lag values to manually backfill label (bfill =7)\n",
        "my_window = Window.partitionBy('msdyn_customerassetid').orderBy(labeled_features.dt_truncated.desc())\n",
        "\n",
        "# Create the previous 7 days \n",
        "labeled_features = (labeled_features.withColumn(\"prev_value1\", \n",
        "                                                F.lag(labeled_features.failure).\n",
        "                                                over(my_window)).fillna(0))\n",
        "labeled_features = (labeled_features.withColumn(\"prev_value2\", \n",
        "                                                F.lag(labeled_features.prev_value1).\n",
        "                                                over(my_window)).fillna(0))\n",
        "labeled_features = (labeled_features.withColumn(\"prev_value3\", \n",
        "                                                F.lag(labeled_features.prev_value2).\n",
        "                                                over(my_window)).fillna(0))\n",
        "labeled_features = (labeled_features.withColumn(\"prev_value4\", \n",
        "                                                F.lag(labeled_features.prev_value3).\n",
        "                                                over(my_window)).fillna(0)) \n",
        "labeled_features = (labeled_features.withColumn(\"prev_value5\", \n",
        "                                                F.lag(labeled_features.prev_value4).\n",
        "                                                over(my_window)).fillna(0)) \n",
        "labeled_features = (labeled_features.withColumn(\"prev_value6\", \n",
        "                                                F.lag(labeled_features.prev_value5).\n",
        "                                                over(my_window)).fillna(0))\n",
        "labeled_features = (labeled_features.withColumn(\"prev_value7\", \n",
        "                                                F.lag(labeled_features.prev_value6).\n",
        "                                                over(my_window)).fillna(0))\n",
        "\n",
        "# Create a label features\n",
        "labeled_features = (labeled_features.withColumn('label', labeled_features.failure + \n",
        "                                                labeled_features.prev_value1 +\n",
        "                                                labeled_features.prev_value2 +\n",
        "                                                labeled_features.prev_value3 +\n",
        "                                                labeled_features.prev_value4 +\n",
        "                                                labeled_features.prev_value5 + \n",
        "                                                labeled_features.prev_value6 + \n",
        "                                                labeled_features.prev_value7))\n",
        "\n",
        "# Restrict the label to be on the range of 0:4, and remove extra columns\n",
        "labeled_features = (labeled_features.withColumn('label_e', F.when(col('label') > 4, 4.0)\n",
        "                                                .otherwise(col('label')))\n",
        "                    .drop(labeled_features.prev_value1).drop(labeled_features.prev_value2)\n",
        "                    .drop(labeled_features.prev_value3).drop(labeled_features.prev_value4)\n",
        "                    .drop(labeled_features.prev_value5).drop(labeled_features.prev_value6)\n",
        "                    .drop(labeled_features.prev_value7).drop(labeled_features.label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "labeled_features.write.mode(\"overwrite\").saveAsTable('machine_data_features')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "microsoft": {},
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# #%%sql\n",
        "\n",
        "# select label_e, count(*) from machine_data_features \n",
        "# group by label_e"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
