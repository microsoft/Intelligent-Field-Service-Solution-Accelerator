{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getSecret(secretName):\n",
        "    linked_service = \"ifmpmvault\"\n",
        "    akv_name = \"ifm-vault\"\n",
        "\n",
        "    # Fetch the key from Azure Key Vault\n",
        "    secretValue = mssparkutils.credentials.getSecret(\n",
        "        linkedService=linked_service,\n",
        "        akvName=akv_name, \n",
        "        secret=secretName)\n",
        "    return secretValue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
        "from azureml.core.model import Model\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "subscription_id = getSecret('subscription-id') \n",
        "resource_group = getSecret('resource-group') \n",
        "workspace_name = getSecret('workspace-name') \n",
        "\n",
        "ws = Workspace(workspace_name = workspace_name,\n",
        "               subscription_id = subscription_id,\n",
        "               resource_group = resource_group)\n",
        "\n",
        "# pull all metrics of best run\n",
        "experiment_name = 'PredictiveMaintenanceExperiment'\n",
        "\n",
        "for automl_run in ws.experiments[experiment_name].get_runs():\n",
        "    best_run, fitted_model = automl_run.get_output()  # We are taking the first run. You can update this if you like to take a different run\n",
        "    break\n",
        "\n",
        "#save the model to a local file\n",
        "model_path = 'failure_prediction_model'\n",
        "joblib.dump(fitted_model, model_path)\n",
        "\n",
        "model_name = \"failure_prediction_model\"\n",
        "registered_model = Model.register(model_path = model_path, # this points to a local file\n",
        "                       model_name = model_name, # name the model is registered as\n",
        "                       tags = {'type': \"classification\"}, \n",
        "                       description = \"Failure Prediction model\", \n",
        "                       workspace = ws)"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
